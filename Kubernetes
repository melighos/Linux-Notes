Kubernetes - open-source container-orchestration system for automating application deployment, scaling, and management. It was originally designed by Google, and is now maintained by the Cloud Native Computing Foundation. It aims to provide a "platform for automating deployment, scaling, and operations of application containers across clusters of hosts". It works with a range of container tools, including Docker. Many cloud services offer a Kubernetes-based platform or infrastructure as a service (PaaS or IaaS) on which Kubernetes can be deployed as a platform-providing service.
Kubernetes coordinates a highly available cluster of computers that are connected to work as a single unit. The abstractions in Kubernetes allow you to deploy containerized applications to a cluster without tying them specifically to individual machines.

=============================================================================
Commands:
kubectl [command] [TYPE] [NAME] [flags]
# command: Specifies the operation that you want to perform on one or more resources, for example create, get, describe, delete
# TYPE: Specifies the resource type. Resource types are case-insensitive.
# NAME: Specifies the name of the resource. Names are case-sensitive. If the name is omitted, details for all resources are displayed.
# flags: Specifies optional flags. For example, you can use the -s or --server flags to specify the address and port of the Kubernetes API server.
# To specify multiple resource types individually: TYPE1/name1 TYPE1/name2 TYPE2/name3 TYPE<#>/name<#>

kubectl config view (show kubernates info about clasters)
kubectl cluster-info (Display endpoint information about the master and services in the cluster)
kubectl get services -A (List all services in the namespace)
kubectl describe service -n <namespace> <servicename> (service info)
kubectl get service -n <namespace> <servicename> -o json/yaml (service info in json/yaml format)
kubectl get ingress -A (show ingress)
kubectl get endpoints -A (show endpoints)
kubectl get nodes (list all nodes in claster)
kubectl describe node <nodename> (node info)
kubectl get pods -A (get all pods in current namespace)
kubectl get pods -o wide -n <namespace> (List all pods in the namespace, with more details)
kubectl create -f /path/to/.yaml (Create one or more resources from a file)
kubectl apply -f /path/to/.yaml (Create a resources using the definition in a .yaml config)
kubectl apply -f <namespace> -R (recursively apply new eviroment using all files in enviroment directory)
kubectl delete -f /path/to/.yaml (Delete resources specified in a .yaml config)
kubectl delete pods -n <namespace> <pod name> (delete and recreate pod)
kubectl delete -f <namespace> -R (recursively delete enviroment)
kubectl describe pod -n <namespace> <pod name> (get pod details)
kubectl logs -n <namespace> <pod name> (get pod logs if eny present)
kubectl exec -it -n <namespace> <pod name> bash (exec bash in pod)
kubectl port-forward -n <namespace> <pod name> 5432:5432 (port forvard from system to pod)
kubectl get configmap <some file> -o yaml > <configname>.yaml (create confignmap from file)

# for each service, for each port, if nodePort is defined, print nodePort
kubectl get svc --all-namespaces -o go-template='{{range .items}}{{range.spec.ports}}{{if .nodePort}}{{.nodePort}}{{.}}{{"\n"}}{{end}}{{end}}{{end}}'
=============================================================================

A Kubernetes cluster consists of two types of resources:
 1.The Master coordinates the cluster:
Master is responsible for managing the cluster. The master coordinates all activities in your cluster, such as scheduling applications, maintaining applications' desired state, scaling applications, and rolling out new updates.
 2.Nodes are the workers that run applications:
Node is a VM or a physical computer that serves as a worker machine in a Kubernetes cluster. Each node has a Kubelet, which is an agent for managing the node and communicating with the Kubernetes master. The node should also have tools for handling container operations, such as Docker or rkt. A Kubernetes cluster that handles production traffic should have a minimum of three nodes.
Nodes communicate with the master using the Kubernetes API, which the master exposes. End users can also use the Kubernetes API directly to interact with the cluster.
Every Kubernetes Node runs at least:
 Kubelet, a process responsible for communication between the Kubernetes Master and the Node; it manages the Pods and the containers running on a machine.
 A container runtime (like Docker, rkt) responsible for pulling the container image from a registry, unpacking the container, and running the application.

Pod - Kubernetes abstraction that represents a group of one or more application containers (such as Docker or rkt), and some shared resources for those containers.
Those resources include:
 Shared storage, as Volumes.
 Networking, as a unique cluster IP address.
 Information about how to run each container, such as the container image version or specific ports to use.
A Pod always runs on a Node.
Pod models an application-specific "logical host" and can contain different application containers which are relatively tightly coupled.
The containers in a Pod share an IP Address and port space, are always co-located and co-scheduled, and run in a shared context on the same Node.

Service is an abstraction which defines a logical set of Pods and a policy by which to access them. Services enable a loose coupling between dependent Pods. A Service is defined using YAML.
The set of Pods targeted by a Service is usually determined by a LabelSelector.
Although each Pod has a unique IP address, those IPs are not exposed outside the cluster without a Service. Services allow your applications to receive traffic. Services can be exposed in different ways by specifying a type in the ServiceSpec:
 ClusterIP (default) - Exposes the Service on an internal IP in the cluster. This type makes the Service only reachable from within the cluster.
 NodePort - Exposes the Service on the same port of each selected Node in the cluster using NAT. Makes a Service accessible from outside the cluster using <NodeIP>:<NodePort>..
 LoadBalancer - Creates an external load balancer in the current cloud (if supported) and assigns a fixed, external IP to the Service. Superset of NodePort.
 ExternalName - Exposes the Service using an arbitrary name (specified by externalName in the spec) by returning a CNAME record with the name. No proxy is used.
A Service routes traffic across a set of Pods. Services are the abstraction that allow pods to die and replicate in Kubernetes without impacting your application. Discovery and routing among dependent Pods is handled by Kubernetes Services.
Services match a set of Pods using labels and selectors, a grouping primitive that allows logical operation on objects in Kubernetes. Labels are key/value pairs attached to objects and can be used in any number of ways.

Scaling out a Deployment will ensure new Pods are created and scheduled to Nodes with available resources. Scaling will increase the number of Pods to the new desired state. Kubernetes also supports autoscaling of Pods. Scaling to zero is also possible, and it will terminate all Pods of the specified Deployment.
Running multiple instances of an application will require a way to distribute the traffic to all of them. Services have an integrated load-balancer that will distribute network traffic to all Pods of an exposed Deployment. Services will monitor continuously the running Pods using endpoints, to ensure the traffic is sent only to available Pods.

ConfigMaps allow you to decouple configuration artifacts from image content to keep containerized applications portable.
------------------------------------------------------------------------------------
Deployment:
The Deployment instructs Kubernetes how to create and update instances of your application. Once you've created a Deployment, the Kubernetes master schedules mentioned application instances onto individual Nodes in the cluster.
Deployments represent a set of multiple, identical Pods with no unique identities. A Deployment runs multiple replicas of your application and automatically replaces any instances that fail or become unresponsive. In this way, Deployments help ensure that one or more instances of your application are available to serve user requests. Deployments are managed by the Kubernetes Deployment controller.

Attach handlers to Container lifecycle events. Kubernetes supports the postStart and preStop events:

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
        lifecycle:
      		postStart:									# Kubernetes sends the postStart event immediately after the Container is created
        		exec:
          		command: ["/bin/sh", "-c", "echo Hello from the postStart handler > /usr/share/message"]
      		preStop:									# Kubernetes sends the preStop event immediately before the Container is terminated
        		exec:
          		command: ["/bin/sh","-c","nginx -s quit; while killall -0 nginx; do sleep 1; done"]
--------------------------------------------------------------------------------------------------------
In the example, the config volume is mounted at /redis-master. It uses path to add the redis-config key to a file named redis.conf.
The file path for the redis config, therefore, is /redis-master/redis.conf. This is where the image will look for the config file for the redis master.

apiVersion: v1
kind: Pod
metadata:
  name: redis
spec:
  containers:
  - name: redis
    image: redis:5.0.4
    command:
      - redis-server
      - "/redis-master/redis.conf"
    env:
    - name: MASTER
      value: "true"
    ports:
    - containerPort: 6379
    resources:
      limits:
        cpu: "0.1"
    volumeMounts:
    - mountPath: /redis-master-data
      name: data
    - mountPath: /redis-master
      name: config
  volumes:
    - name: data
      emptyDir: {}
    - name: config
      configMap:
        name: example-redis-config
        items:
        - key: redis-config
          path: redis.conf
---------------------------------------------------------------------------------------------------------------------