Docker - utility to pack, ship and run any application as a lightweight container.
Image(OS,dependencies,application code) - snapshot to run in container.
Dockerfile - list of steps to perform in Container using specified Image

commands:
docker info (general docker info)
docker ps (show running containers)
docker ps -a (show all containers)
docker stats (running containers info)
docker container prune (remove all stopped containers)
docker network ls (show all docker networks)
docker volumes ls (show all docker volumes)
docker rm --force <name> (remove container)
docker system/container/image/volume/network prune -a (clean up unused containers, networks, images)
docker container rm <id>

docker exec <container-id|container-name> <command> (execute command in container)
docker exec -it <container-id|container-name> /bin/bash (start a shell inside a Docker container)
docker stop <container-id> (stop container)
docker restart <container-id> (restart container)
docker attach <container-id|container-name> (attach to a running container)
docker cp <container>:/path/ /path/on/host (copy from container to host machine)

docker logs <container-id|container-name> (get logs from container)
docker logs --tail 50 --follow --timestamps <container-id|container-name> (get logs from container)
docker inspect <container-id|container-name> (get datailed info about container)

docker run (run container with specified arguments)
docker run --rm -ti ubuntu /bin/bash (execute bash in ubuntu container with interactive shell, and remove conteiner after logout)
docker run -d --privileged=true --name=<contname> <image-name> (“privileged” container is given access to all devices)
docker run -ti -d --privileged=true --name=<cont-name> <image-name>  "/sbin/init"
docker run --publish 8000:8080 --detach --name <name> <image:version> (--detach - run in the background, --publish - expose port)
docker run --name postges --rm -it -v $(pwd):/root --network host postgres bash
docker run -it --rm --link db:db postgres psql -h db -U postgres
docker run -it --rm -m 256m --memory-swap 256m --oom-kill-disable stress --vm 1 --vm-bytes 2000M --vm-hang 0 
docker run -it -p 8545:8545 -p 30303:30303 -v $PWD:/root/.ethereum ethereum/client-go --rpc --rpcaddr "0.0.0.0" --syncmode full
docker run --network=host --rm -ti ubuntu /bin/bash (host - use host network)
docker run -d -t -i -e REDIS_NAMESPACE='staging' -name container_name dockerhub_id/image_name (-e pass environment variables)
docker run -it --rm --cap-add=NET_ADMIN --device=/dev/net/tun --name=<contname> <image-name> (device=/dev/net/tun - create device, cap-add - add capabilities)

docker-enter <container-id|container-name> (get a shell inside the container)
docker-enter <container-id|container-name> df -h (run commands in container)

#Out of the box, Docker creates three networks:
#    bridge - An automatically generated network with a subnet and a gateway.
#    host - Allows a container to attach to the host's network.
#    none - A container-specific network stack that lacks a network interface.
docker network ls (view Docker networks)
docker network inspect <network-name> (detailed info about network)
docker network create --driver=bridge --subnet=172.20.0.0/16 --gateway=172.20.1.10 <network-name> (create new network)

arguments:
-i (interactive, keep STDIN open)
-t (allocate a pseudo-TTY)
-p container-port:local-port (bind container port to local port)
--rm (remove after stopped)
--name (give container a name)
-m 256m (set memory limit)
--memory-swap 256m (set swap limit)
--oom-kill-disable (hung container if it's memory consumption exceeds your -m VALUE, or otherwise it will be just killed by oom-killer)

------------------------------------------------------------
docker image command:
docker image ls -a (show all local images)
docker rmi -f <image id>
docker build --tag <image name> . (build docker image in current directory)
dockr build -t <name> -f ./.dockerfile . (-t tag, -f specify docker file to use)
docker save <image-name> > <image-name>.tar (create a tarball of our local docker image)
docker load -i <image-name>.tar (load image from a tarball)

docker build --network=host -t wemine-kafka-producer:prod . (host - use host network)
----------------------------------------------------------------------
Dockerfile for building image examples:
---
FROM huggla/alpine-slim:20180927-edge as stage1

ARG APKS="<add package with executable here>"

COPY ./rootfs /rootfs

RUN apk --no-cache add $APKS \
 && apk --no-cache --quiet info > /apks.list \
 && apk --no-cache --quiet manifest $(cat /apks.list) awk -F " " '{print $2;}' > /apks_files.list \
 && tar -cvp -f /apks_files.tar -T /apks_files.list -C / \
 && tar -xvp -f /apks_files.tar -C /rootfs/ \
 && mkdir -p /rootfs/usr/local/bin \
 && cp -a <executable> /rootfs/usr/local/bin/

FROM huggla/base:20180927-edge

ENV VAR_LINUX_USER="<Linux user to run final command>" \
    VAR_FINAL_COMMAND="<command for running executable>"
---
FROM golang:1.11-alpine AS build

# Install tools required for project
# Run `docker build --no-cache .` to update dependencies
RUN apk add --no-cache git
RUN go get github.com/golang/dep/cmd/dep

# List project dependencies with Gopkg.toml and Gopkg.lock
# These layers are only re-built when Gopkg files are updated
COPY Gopkg.lock Gopkg.toml /go/src/project/
WORKDIR /go/src/project/
# Install library dependencies
RUN dep ensure -vendor-only

# Copy the entire project and build it
# This layer is rebuilt when a file changes in the project directory
COPY . /go/src/project/
RUN go build -o /bin/project

# This results in a single layer image
FROM scratch
COPY --from=build /bin/project /bin/project
ENTRYPOINT ["/bin/project"]
CMD ["--help"]
---------------------------------------------------------------
Files and Directories to ignore when building docker image:

.dockerignore:
# Remove folders:
/dev 
/proc
/sys
/tmp
/run
/mnt
/media
/lost+found
/var/log
/var/cache

# Remove useless heavy files like /var/lib/scrapyd/reports.old
**/*.old
**/*.log
**/*.bak

# Remove docker
/var/lib/lxcfs
/var/lib/docker
/etc/docker
/root/.docker
/etc/init/docker.conf

# Remove the current program
/.dockerignore
/Dockerfile
-----------------------------------------------------------------
Docker Compose - tool for defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application’s services.
Then, with a single command, you create and start all the services from your configuration.
docker-compose.yml - file that contains the configuration for creating the containers, exposing ports, binding volumes and
connecting containers through networks required for your app to work.
Compose preserves all volumes used by the services defined in the compose file, thus no data is lost when the containers are recreated using docker-compose up.

commands:
docker-compose up -d (execute docker-compose.yaml, -d - detach)
docker-compose -f /root/docker-compose.yml up -d (execute docker-compose.yaml from another location)
docker-compose down (bring down docker-compose project, also removes the stopped containers as well as any networks that were created)
docker-compose rm (remove docker-compose project)
docker-compose start <service> (start docker-compose service)
docker-compose stop <service> (stop docker-compose service)
docker-compose restart <service> (restart docker-compose service)
docker-compose ps (list docker-compose containers)
docker-compose exec <servicename> sh/bash (Attach to container from docker-compose)
docker-compose logs -f (show docker-compose project logs, -f - follow logs)
docker-compose events <servicename> (Stream container events for every container in the project)

docker-compose build
docker-compose scale <service-name=3> (scale service defined in Docker compose configuration, old)
docker-compose up -d --scale <service-name=5> (specify the scalability of any particular service, new)
-----------------------------------------------------
docker-compose.yml examples:

version: '3.3'
services:
  influxdb:
    image: influxdb:latest
    env_file: configuration.env
    container_name: influxdb
    ports:
      - '8086:8086'
    volumes:
      - /opt/docker/influxdb:/var/lib/influxdb
    restart:
      always

  grafana:
    image: grafana/grafana
    container_name: grafana
    depends_on:
      - influxdb
    env_file: configuration.env
    links:
      - influxdb
    ports:
      - '3000:3000'
    volumes:
      - /opt/docker/grafana:/var/lib/grafana
      - /opt/docker/grafana/provisioning/:/etc/grafana/provisioning/
      - /opt/docker/grafana/dashboards/:/var/lib/grafana/dashboards/
    restart:
      always

networks:
  default:
    driver: bridge
    ipam:
      driver: default
      config:
      - subnet: 10.10.0.0/16 

---------
version: '3.6'
services:
  influxdb:
    image: influxdb:1.7-alpine
    env_file: configuration.env
    ports:
      - '8086:8086'
    command: >
      sh -c "python manage.py wait_for_db &&
             python manage.py migrate &&
             python manage.py runserver 0.0.0.0:8000"
    volumes:
      - influxdb_data:/var/lib/influxdb

  grafana:
    image: grafana/grafana:6.3.3
    depends_on:
      - influxdb
    links:
      - influxdb
    ports:
      - '3000:3000'
    environment:
      - RACK_ENV=development
      - SHOW=true
      - SESSION_SECRET

    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/provisioning/:/etc/grafana/provisioning/
      - ./grafana/dashboards/:/var/lib/grafana/dashboards/

volumes:
  grafana_data: {}
  influxdb_data: {}
--------
version: '2'
services:
  zookeeper:
    image: wurstmeister/zookeeper
    ports:
      - "2181:2181"
  kafka:
    build: .
    ports:
      - "9091-9094:9092"
    environment:
      KAFKA_ADVERTISED_HOST_NAME: 127.0.0.1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_CREATE_TOPICS: "Topic1:1:3,Topic2:1:1:compact"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
